# Fine-Tuning Mistral-7B with PEFT and QLoRA ğŸš€

Ce projet montre comment fine-tuner le modÃ¨le **Mistral-7B-Instruct** en utilisant la mÃ©thode **QLoRA** (Quantized LoRA) et la bibliothÃ¨que **PEFT (Parameter-Efficient Fine-Tuning)**. Il utilise le dataset `iamtarun/python_code_instructions_18k_alpaca` et le framework `transformers` de Hugging Face avec `trl`.

---


## ğŸ§© Technologies utilisÃ©es

- `transformers`
- `datasets`
- `peft`
- `trl` (pour `SFTTrainer`)
- `bitsandbytes` (quantization)
- `accelerate` (multi-GPU support)

---

## âš™ï¸ Installation des dÃ©pendances

```bash
pip install --upgrade peft accelerate bitsandbytes datasets trl

# ğŸ§¬ RÃ©sumÃ© Automatique dâ€™Articles Scientifiques MÃ©dicaux avec LLM

Ce projet a pour objectif de dÃ©velopper un **systÃ¨me de rÃ©sumÃ© automatique** basÃ© sur un **grand modÃ¨le de langue (LLM)** afin de synthÃ©tiser des publications scientifiques en mÃ©decine. Le systÃ¨me est optimisÃ© pour deux types spÃ©cifiques de publications :

- ğŸ§ª **Les essais contrÃ´lÃ©s randomisÃ©s (ECR)**
- ğŸ”¬ **Les Ã©tudes observationnelles**

> ğŸ¥‡ **Dans ce projet j'ai obtenu la 1Ã¨re place dans la compÃ©tition Kaggle** [M2 - RÃ©sumÃ© d'articles scientifiques](https://www.kaggle.com/competitions/m-2-maliash-resume-darticles-scientifiques).

---

## ğŸ¯ Objectifs du projet

- CrÃ©er un modÃ¨le robuste capable de produire des rÃ©sumÃ©s fiables Ã  partir de textes scientifiques longs et complexes.
- Comparer les performances Ã  lâ€™aide de la mÃ©trique **ROUGE**, utilisÃ©e pour Ã©valuer la qualitÃ© dâ€™un rÃ©sumÃ© automatique par rapport Ã  un rÃ©sumÃ© de rÃ©fÃ©rence.

---

## ğŸ§  Approche

- Utilisation de modÃ¨les de type **Large Language Models (LLMs)**, comme ceux basÃ©s sur la famille **T5 / BART / GPT**.
- PrÃ©traitement soignÃ© du texte scientifique (normalisation, nettoyage des sections).
- EntraÃ®nement supervisÃ© sur des rÃ©sumÃ©s de rÃ©fÃ©rence rÃ©digÃ©s par des experts.
- Ã‰valuation via les scores **ROUGE-1, ROUGE-2 et ROUGE-L**.

---

## ğŸ“‚ Contenu du dÃ©pÃ´t

- `notebooks/` : Contient le notebook de prÃ©paration de donnÃ©es, fine-tuning et Ã©valuation.


---

## ğŸ“Š DonnÃ©es

Les donnÃ©es sont fournies par la compÃ©tition Kaggle :
- Texte complet dâ€™articles scientifiques
- RÃ©sumÃ©s de rÃ©fÃ©rence rÃ©digÃ©s manuellement
- MÃ©ta-informations sur le type dâ€™Ã©tude

Lien vers la compÃ©tition : [https://www.kaggle.com/competitions/m-2-maliash-resume-darticles-scientifiques](https://www.kaggle.com/competitions/m-2-maliash-resume-darticles-scientifiques)

---

## ğŸ§ª Ã‰valuation

Lâ€™Ã©valuation est basÃ©e sur la **mÃ©trique ROUGE** :
- **ROUGE-1** : n-grammes unigrams
- **ROUGE-2** : bigrams
- **ROUGE-L** : plus longue sous-sÃ©quence commune

Le modÃ¨le proposÃ© a atteint des performances exceptionnelles, se classant **1er dans le leaderboard final** de la compÃ©tition.

---

## ğŸš€ Reproduire les rÃ©sultats

1. **Cloner le dÃ©pÃ´t** :
   ```bash
   git clone https://github.com/ton-utilisateur/nom-du-repo.git
   cd nom-du-repo
